{"pages":[{"title":"About This Website","text":"關於我嗨嗨大家好, 我是 Mike, 大學以及研究所都是念資訊管理, 並於 2019 畢業後成為菜鳥工程師, 會想寫部落格主要是因為過去遇到問題都是上網 Google 前人的經驗來解決, 而每次找到解答都會打從心底感謝前人留下的紀錄, 所以也想自己來寫一個部落格, 用來記錄一些生活瑣事以及工作上遇到過的問題, 期盼自己的紀錄也可以在未來幫助到需要的人, 若文章中有哪裡寫錯或是需要改進的地方都歡迎提出, 感謝大家 XD 域名的由來因為英文名稱為 Chun Tsai, 因此就取 ctsai 當作域名, 而選用 .dev 作為頂級域名而不是 .com 純粹是因為考慮 .com 原本是用來表示商業用途, .dev會比較適合作為部落格的頂級域名使用, 且之前偶然看到這篇 文章 指出 .dev 相較之下會比較安全, 因此就選用 .dev 最為最終的頂級域名 〔´∇｀〕 Blog 前身該網站前身為 https://miketw.com , 當時使用整套的 Google 服務作為網站解決方案, Google App Engine + Google Cloud SQL + Google Doamin 搭建, 當時的想法是可以把部落格文章跟 Side Project 放在一起, 而 Side project 的部分勢必會用需要用到資料庫, 因此就說從無到有搭建網站, 順便玩一下 Google Cloud Platform 的服務, 確實如同當初想像一樣, 從頭搭建的自由度的確很大, 但隨著時間推進漸漸發現網站文章/檔案管理以及維護一些眉眉角角實在太費工, 考慮到部落格還是希望以發表文章為主, 因此最終決定將兩者拆開, 文章的部分會改在此部落格分享, 而原本搭建的網站未來文章就不會再更新, 轉型成為只單純放一些實作小功能的地方 (〃￣︶￣)人(￣︶￣〃)","link":"/about/index.html"},{"title":"筆記總整理","text":"Google Code Review Overview Google Code Review - Overview 篇 Developer Google Code Review - Developer 篇 Reviewer Google Code Review - Reviewer 篇 - 1 Google Code Review - Reviewer 篇 - 2 Google Code Review - Reviewer 篇 - 3 Google Code Review - Reviewer 篇 - 4 Google Code Review - Reviewer 篇 - 5 Google Code Review - Reviewer 篇 - 6","link":"/collections/index.html"}],"posts":[{"title":"2019.12 九州旅遊","text":"2019.12 九州旅遊前言 十月底剛結束了4 個月的軍事訓練役，距離原先12月開始工作時間還有一個月，剛好又看到 Facebook 上面的廣告寫到日北楓葉盛開，心血來潮下就決定跟著家人一起到日本進行旅遊，而過去跟父母出遊往往都是跟團，不過因為過往經驗跟團往往時間較為緊湊，於是這次選自由行的方式進行旅遊。 行程細項 日期：2019/12/02 - 2019/12/07 天數：5天 地點：日本北九州 去程航空：華航 返程航空：華航 去程航行時間：06:50 - 09:55 返程航行時間：18:30 - 20:10 行程細項 第一天 凌晨四點左右搭車前往機場，並在機場隨便吃一下後就準備登機，接著在機上吃早餐，下飛機後先到飯店放行李，並搭著地鐵到太宰府遊玩。 搭飛機的父母 前兩天住的飯店 太宰府 太宰府 太宰府的梅枝餅 太宰府的楓葉 太宰府街道 第二天 第二天搭乘由布院之森到由布院，並走訪金鱗湖，晚上回到博多車站吃飯~ 由布院街道 由布院街道 由布院街道由布院街道上的餐車 由布院街道 金鱗湖 由布院童話村Floral Village 童話村當中的松鼠 由布院之森 回程の我 &gt;&lt; 第三天 第三天搭乘 JR 音速到門司港，門司港吃燒咖哩，搭船到下關，並到唐戶市場買海鮮、昆布，走訪馬關條約的簽約地點春帆樓，以及赤間神宮，晚上回到博多車站的聖誕市集逛逛。 博多地鐵站 門司港拍照的爸媽 門司港必吃的燒咖哩 渡船口 唐戶市場 馬關條約春帆樓，李鴻章座位 赤間神宮 赤間神宮前面拍照的小朋友 博多車站聖誕市集 博多車站聖誕市集 第四天 搭乘 JR 海鷗到長崎，平和紀念公園，並到核爆地觀摩，晚上到博多運河城光逛逛~ JR 海鷗 平和紀念公園 象徵和平的雕像，指天的右手象徵著原子彈的威脅，水平伸展的左手象徵和平。 平和紀念公園的雕像 象徵祈福的紙鶴 平和紀念公園 爆心地公園的雕像，廣島與長崎原子彈爆炸發生在第二次世界大戰末期，美軍在1945年8月6日與8月9日，分別在日本的廣島市和長崎市投下兩枚原子彈，這是歷史上人類第一次且唯一一次在戰爭中使用核武器 ,資料來源:維基百科。 爆心地公園中為喪者的祈福紙球、紙鶴。 爆心地公園中的雕像。 博多運河城。 博多運河城。 第五天 做地鐵到天神，回國前買點東西回去～ 天神町地下街 午餐拉麵 日本必來的免稅店 bic camera 購買的鍵盤 花費 項目 單價 數量 &nbsp;&nbsp;&nbsp; 金額 (NTD) JR_PASS 三日卷 2280 3人 6460 Klook 機場接送 672 1 趟 672 台北 福岡 來回機票 8112 3人 24336 JR_PASS 湯布院來回 座位預定票 560 3 人 1679 Miyako Hotel Hakata (五星 ,三人房 , 附早餐)&nbsp;&nbsp;&nbsp; 6541 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2 晚 13,083 Hotel Wing (三星,兩人房 , 無早餐) 3011*2 &nbsp;&nbsp; 2 晚 12,047 SUGOCA 悠遊卡 614 2 張 1,268 總價 59924.9","link":"/20191211/2019_12_Kyushu/"},{"title":"2019 淘寶雙十一購物","text":"2019 淘寶雙十一購物以下為雙十一的解釋 擷取自wikipedia雙十一（英文：double 11），是指每年11月11日的大型促銷活動，最早起源於中國電商巨頭阿里巴巴旗下購物網站在2009年11月11日舉辦的「淘寶商城促銷日」，現已演變成全行業一年一度的覆蓋線上線下的購物活動，及影響全球零售業的消費現象。「雙十一」的發起者阿里巴巴CEO張勇將雙十一稱為「商業界的奧林匹克」[1]。2012年11月11日網路購物全日銷售額超過美國網路星期一，成為全球最大的網際網路的購物節日。[2] 是許多商家都會在雙十一展開特價，今年當然也不意外許多商家也展開特價，而我抱著看看的心態到淘寶看看，結果一個禮拜後這些東西就莫名奇妙出現在我家了……. 包裹們 鍵盤手拖: 276 元 整線束帶: 81 元 / 五公尺 保護套： 80 元 / 兩個 桌面整線器: 85 元 / 兩個 三合一磁吸充電線: 76 元 / 一條 磁吸充電線動畫 TOPK月牙快充磁吸充電線強磁: 127 元 / 一條 保護貼：76 元 / 兩張 品項 價格 桌面理線器 85 漁網磁吸充電線 67 月牙磁吸充電線 127 五公尺整線束帶 81 閃魔保護貼 *2 152 實木手托 276 手機保護殼 *2 80 總價 868","link":"/20191111/2019_taobao_shopping/"},{"title":"TEST CI&#x2F;CD","text":"dummy content.","link":"/20230909/TEST-CI-CD/"},{"title":"部落格的誕生","text":"退伍後的生活回想起兩年前的今天，我還是個剛上研究所兩個月的碩一新生，而兩年後的今天我已從碩班畢業，並且完成兵役，說來實在非常幸運,我在論文口試日期都還有確定日期的情況下，便申請了提前入伍，而也如願在 7/18 入伍，並在 10/30 順利的結束兵役，真的非常感謝教授，而在當兵的這段期間其實我也一直在思考未來的方向。 退伍後距離答應公司到職日其實還有一個月左右的時間，於是就利用這個月的時間到新竹找女友，大約一週三天，每天的行程就是起床載她去上班然後在自己到圖書館唸書，雖然已經在工作的朋友都建議應該要出去玩的,因為上班後可以利用的自由時間會變得非常短，但想想之後短時間內應該沒有機會能跟女友一起住，所以就利用這一個月的時間體驗一下外宿生活，畢竟除了去年暑假到台中的實習在台中住了兩個月外從小到大我都是住家裡XD 正式上班前的圖書館日常 建立網站原因當然讀書、刷題其實說不上枯燥乏味，雖然題目跟書中的內容都不同，但每天都一樣的生活其實還是蠻容易膩的，於是想起過去曾學過 django, css, html 等等，所以就決定利用空閒時間做個Blog 可以記錄一下生活點滴，過去大學時期記得班上有個女生作文很厲害並且常常看到她分享一些自己的文章，當初只覺得字好多，但現在回頭想想如果能用文字記錄生活何嘗不是一件壞事呢，畢竟有些事情不記錄下來可能時間久了就忘了~ 網站部署環境雖然現在有很多服務像是 WEEBLY, WORDPRESS 等等，都可以幫助使用者快速地建立一個網站，但是在眾多因素的考量下我還是決定自己從頭弄一個，也算是另類的side project !? 最後也很慶幸自己能生在這樣的年代，因為網路的普及如果想要學習任何新知識都變得非常容易，網站的部署，後端伺服器，網域名稱註冊，等等都已經變得非常容易。網站後端不需要像過去自己用一台電腦，甚至連到 AWS, GCP 上面租用一台Server去做部署 都可以省掉，因為這樣還要去部署Server 作業的環境，而最終選用 Serverless 的架構，減少了維護成本與時間，利用 Google App Engine 來部署網站，因為過去學習的經驗曾經租過 Google 的 VM Instance 說實在話環境的設定真的蠻繁瑣的，而也在部署的當天購買了網域名稱 mikeTW.com，也因為這些方便的服務從開始做到實際上線只花了5天的時間，至於網站還有很多功能不完整會在未來慢慢的補齊，但至少已經可以開始寫一點生活的大小事了～","link":"/20191031/blog_init/"},{"title":"解除 Mega 單日流量限制","text":"解除 Mega 流量限制 (2021/04)問題描述Mega 每日有 5GB 流量限制，若要下載更大的檔案則需要付費升級。 針對大檔案下載解法若要下載超過 5 GB 檔案可以使用以下方式完成下載 等待 6 小時冷卻時間 (免費, 耗時間) 升級付費會員 (付費) 透過 proxy 繞過 下載限制 (免費) 本篇文章會針對第三種方式進行大檔案下載，並使用國外大大所開源的專案 megabasterd 進行 Proxy 設定, 透過幾步驟簡單設定即可繞過檔案限制。 Megabasterd 使用方式安裝環境 (若電腦有安裝過可以跳過該步驟)由於作者是使用 java 刻的，所以必須安裝此環境程式可以順利跑起來～下載網址: https://java.com/zh-TW/ 下載主程式下載網址: https://github.com/tonikelope/megabasterd/releases/tag/v7.40這邊可以看到多種版本, 請下載 .jar 檔結尾的 (25.1MB 那個) 設定 API Key運行主程式 12345# 切換到主程式所在路徑 這邊假設放在桌面下$ cd ~/Desktop# 運行主程式$ java -jar test.jar 這時應該會跳出請您設定 api key 的界面 這邊可以隨便打只要把隨機產生的 App key 記下來即可 這時回到主程式設定對應的 App key,Edit -&gt; Settings -&gt; Advanced key -&gt; Mega api key -&gt; 填入剛剛產出的 key 設定 proxy https://us-proxy.org/ http://free-proxy.cz/en/proxylist/country/TW/all/ping/all 透過上方網址可以拿到許多可以用的 proxy。 EDIT -&gt; Settings 往下拉可以看到 smart proxy,勾選 Use SmartProxy,並將上面得到的proxy 網址按照 IP:Port 格式填入即可。 Let’s Dance, Baby終於完成所有設置，之後下載檔案只須執行 Let’s Dance, Baby 這步驟即可XD 點擊 File -&gt; New Download -&gt; 填入需要下載的 mega 檔案網址 -&gt; 按下 Let’s dance, baby XD 可以看到即使是大於 5GB 檔案也能完成下載 感謝收看～ References https://github.com/tonikelope/megabasterd https://us-proxy.org/","link":"/20211013/crack_mega_limit/"},{"title":"使用 CircleCI 完成 Google App Engine 自動部署","text":"要解決的問題事情是這樣子的，最近因為剛好有一些空閒時間，於是想要在原本部署在 Google App Enginee 的部落格進行排版的調整，並實做一些小功能，然而卻發現以前的開發，部署流程有些繁瑣，剛好工作上有接觸到 CI/CD 的概念，因此想說不如就趁此機會把也把 CI/CD 的實作應用到專案上，最終決定以 CircleCI 作為 CI/CD 工具以簡化之後的開發流程，並且順手記錄下來，想像上只要是部署在 GCP 上面的服務應該都通用 XD 導入前的開發部署流程在開始之前我們先來看看導入前後的部署流程會是長怎樣XD過去的開發流程如下 本地開發測試 將本地端變更的 Code 推上 Github Repository 將本地端變更的 Code 推上 GCP 導入後的開發部署流程整併 CircleCI 後的流程 本地開發測試 將變更的 Code 推上 Github, Github 自動去 trigger CircleCI 執行後續測試 &amp; 部署上 GCP 的工作 一些隱藏的優點雖然看起來只省了一個步驟好像沒有帶來多少好處，但事實上還有一些隱藏的優點會在未來慢慢體現，以下為一些隱藏好處的例子: 導入 CI/CD 前可能測試好但是忘記部署，這時過了一段時間後想要到網站上面玩玩新的功能，卻發現找不到該功能，這時就要自己去 GCP 上面追部署的 Log, 看是哪一次忘記推上去 QAQ, 而這種情況若導入 CI/CD 後就可以確保，push 上 repository 跟 deploy 兩步驟被一起執行 ~ 假設 deploy 以及 test 會花很長的時間，在導入 CI/CD 後你可以把修改過的 code push 上 repository，然後安心的去做其他事情，靜待 CI/CD 的結果即可，這邊要推薦一下 CircleCI 會把結果直接送到你的 mail 中，方便大推 ~ 多一個地方可以看到過去每次 test 以及 deploy 的紀錄 開發環境 Circleci Google App Engine 實作細節CircleCI 基本設定 首先到 CircleCI 綁定 github 綁定後使用選擇 Projects → 對應專案按下 Set Up Project 接著選擇 Write your own using our starter config.yml template 按下按鈕後會自動幫你生成 default 的 config.yml 檔案, 點擊右上方的 Commit and Run 這時如果你回到對應的 Github repository 查看你會發現 除了原本的 branch 外，會多出一個 branch circleci-project-setup 而也可以從 CircleCi 的 dashboard 上面看到剛剛成功的執行結果 點擊 say-hello 可以看到剛剛對應生成 config.yml 所定義的步驟 如果到這裡都沒有問題，恭喜你，已經順利將 Github repository 綁上 CircleCI 了~ Google App Engine deployment 設定接著我們需要在 Google App Engine 進行一些設定 設定 CircleCI 環境變數 點擊 project setting 而後點擊 Add Environment Variable，先停在這頁, 我們先去 GCP 取得這三個變數 XD 到 GCP 的 IAM 中，點擊 服務帳戶，點擊動作裡的三點圖標，點擊管理金鑰 點擊建立新的金鑰，並選取 JSON 格式 這時會到剛剛 CircleCI 環境變數的那頁 並且設定以下三個變數 GCLOUD_SERVICE_KEY (必要) GOOGLE_COMPUTE_ZONE (可選擇) GOOGLE_PROJECT_ID (可選擇) GCLOUD_SERVICE_KEY 的值為剛剛我們下載 JSON 裡面所有的值，請直接將整個 JSON 的內容複製貼上~ 最後到 GCP 中啟用服務 APP Engine Admin API 在專案中新增對應設定檔接著到專案的根目錄中去添加 CircleCI 的設定檔案 config.yml 123456789101112131415161718192021222324252627282930313233version: 2.1jobs: build_and_deploy: docker: - image: google/cloud-sdk:slim steps: - checkout - run: name: Install Env command: | apt install -y python-pip &amp;&amp; \\ python3 -m pip install -r requirements.txt - run: name: Deploy to Google Engine command: | echo ${GOOGLE_PROJECT_ID} echo ${GOOGLE_COMPUTE_ZONE} echo ${GCLOUD_SERVICE_KEY} &gt; /tmp/sa_key.json gcloud auth activate-service-account --key-file=/tmp/sa_key.json rm /tmp/sa_key.json gcloud --quiet config set project ${GOOGLE_PROJECT_ID} gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE} gcloud --quiet app deploy workflows: version: 2 build_and_deploy: jobs: - build_and_deploy: filters: branches: only: - master 簡單看一下 script 裡面做了什麼事情, 首先我們選用 google/cloud-sdk:slim docker image 作為 CircleCI 的運行環境(slim 版本的比較輕量), 然後定義了一個 job build_and_deploy, Job 內有兩件事情要做 Install Env &amp; Deploy to Google Engine, 分別進行安裝環境以及部署上雲端，這邊會看到會去拉剛剛我們設定的環境變數 GCLOUD_SERVICE_KEY, 最後部署到 Google App Engine. 檢查 CICD 是否正常運行 1234$ git checkout -b &quot;circleci-project-setup&quot;$ git add .$ git commit -m &quot;test&quot;$ git push origin circleci-project-setup 到 Github 中發 Pull Reuqest 到 master branch 此時應該會看到以下畫面 這時可以回到 CircleCI 利用對應的 Commit 編號去看對應的 Log 對應執行的指令 這時再回到 GCP 上面就可以看到成功部署拉～ 部署優化 (optional)剛剛我們已經成功地將網站透過 CircleCI 部署上 GCP 了, 但是有沒有地方可以做得更好呢？其實是有的，我們在建立CircleCI 環境時會利用 virtual environment 去建立環境，而這步驟其實是可以快取的，只要在每次運行前先 restore_cache 並在運行結束 save_cache 就可以達到快取的功能, 完整的代碼如下。 完整的 .circle/config.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748version: 2.1jobs: build_and_deploy: docker: - image: google/cloud-sdk:slim steps: - checkout - restore_cache: # **restores saved dependency cache if the Branch key template or requirements.txt files have not changed since the previous run** key: deps1-{{ .Branch }}-{{ checksum &quot;requirements.txt&quot; }} - run: name: Install Env command: | apt-get install -y python3-venv python3 -m venv venv . venv/bin/activate pip install -r requirements.txt # command: | # apt install -y python-pip &amp;&amp; \\ # python3 -m pip install -r requirements.txt - run: name: Run Test Cases command: &quot;echo dummy test case : Hello, World!&quot; - save_cache: # ** special step to save dependency cache ** key: deps1-{{ .Branch }}-{{ checksum &quot;requirements.txt&quot; }} paths: - &quot;venv&quot; - run: name: Deploy to Google Engine command: | echo ${GCLOUD_SERVICE_KEY} &gt; /tmp/sa_key.json gcloud auth activate-service-account --key-file=/tmp/sa_key.json rm /tmp/sa_key.json gcloud --quiet config set project ${GOOGLE_PROJECT_ID} gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE} gcloud --quiet app deploy workflows: version: 2 build_and_deploy: jobs: - build_and_deploy: filters: branches: only: - master 比較一下差異 快取前快取後 結論感謝您的收看，今天我們嘗試了 整合 CircleCI CI/CD 自動部署上 Google App Engine 利用快取優化部署時間 參考連結 https://circleci.com/docs/ https://hub.docker.com/r/google/cloud-sdk/ https://ithelp.ithome.com.tw/articles/10230182","link":"/20211015/gcp-circleci/"},{"title":"Google Code Review - Overview 篇","text":"此篇為 Google Code Review Overview 的介紹, 主要擷取自 Google Code Review Guideline 的內容, 後續會陸續分為 Reviewer 以及 Author 兩部分文章紀錄，若內容有誤歡迎大大們指正，感激不盡 d(`･∀･)b 介紹reference: https://blog.claudiupersoiu.ro/2011/10/04/code-quality-and-development-time/lang/en/ 大家都知道開發系統時系統的 code quality 以及健康度會隨著時間下降，為了避免這種問題 code review 就顯得非常重要，藉由多一些人把關檢查來提升品質，而 Google 也提出了內部的一些 review, author 的準則，以下就簡單整理一下 XD 應該要被 Review 的事項 Design: 提交的 code 是否有更好的設計? 設計是否會跟現有系統造成衝突，作法是否符合原本系統的 convention 等等 Functionality: 確認提交的 code 行為符合作者的預期? 行為是否對使用者造成問題等等? Complexity: 是否可寫的更簡潔? 未來的開發者是否能直接讀 code 就知道在幹嘛，寫法是否方便往後修改或是 reuse ? Tests: 修改部分對應的測試是否有一併被加上呢? Naming: 類別、方法、變數的命名是否遵循規範? 可讀性及代表涵義是否清楚? Comments: comments 是否清楚且有幫助? Style: coding style 是否有符合規範? Documentation: 對應的文件是否有一併更新? 挑選適合的 Reviwer請挑選最合適的 Reviewer, 挑選了解該代碼的人, 可能是過去的 owner, 有時一個 CL (PR) 會需要請不同人去 review 不同段的代碼, 請找到最適合的 reviewer, 若該人無法進行 review 至少也要 CC 他們, 通知他們你所進行的更動。 In-Person Reviews若是跟 Reviewer 一起進行開發，則該段代碼可以視為已 review, in-personal review, reviewer 提出問題, 開發者只在 reviewer 提出問題時回答並進行修改。 Conclusion感謝您的收看, 此篇為較粗略的介紹, 將在後續文章詳述細節的部份 (つ´ω`)つ 歡迎點擊這邊 Google Code Review 全系列筆記瀏覽 code review guideline 全系列筆記文章 :)","link":"/20211128/google-code-review-0/"},{"title":"Google Code Review - Author 篇","text":"多人軟體開發流程中除了開發及測試外，另一相對重要卻常常被忽略掉的應該就是 code review process, 專案的開發過程中為了讓 code 品質可以更好，通常在功能開發完成要合併到 master branch 前都會需要至少一位相關的同事給予授權 (approval) 才能將修改的 code 合併進 master branch 中而在審核的過程就稱為 code review，然而事否有一套統一的準則能加速 code review 的過程並且提高 code review 的品質呢? 在網路上看了一些文章後有幸找到 Google 提出的 code reivew guideline，而當中分為 Reviewer 以及 Author 兩個部分，打算用兩篇文章分別筆記一下 XD(若有寫錯的部分也請大大們鞭小力一點)，本篇文章為 Author (提出修改者) 相關的筆記~ 何謂 Code Review (What)code review 又稱作 changelist, change, patch, pull-request, 泛指開發者在本地做完變更後將修改內容合併到 master branch 前的審核工作，在審核批准後 code change 就會合併到 Master branch 並且部署到正式產品服務中。 示意圖reference: https://dev.to/saymy__name__/git-workflow-for-periodic-jenkins-builds-801 為何需要 Code Reivew (Why) 多一個人把關, 確認語法,架構,功能沒有問題 確保功能符合預期 確認 coding convention 符合規範 藉由資深同事 review 來告訴你哪邊可以寫得更好, 以及提點你可能遺漏的部分 performace improvement 何時需要 Code Reivew (When)可以藉由上圖得知在 code review 通常發生在 merge code 到 master branch 之前，但其實即便是單獨開發的 project 只要能標出特定範圍都可以進行 code review XD 在哪邊進行 Code Review(Where)通常發生在 github 上面的 File Change 中， bitbucket 或是其他的開發整合工具應該也有對應的頁面但自身並沒有嘗試過，就不在此進行詳細討論(́◉◞౪◟◉‵) 誰需要進行 Code Review(Who) project 主要 contributors 過去對此 feature 有過相關開發經驗的開發者 Team 內此專案的負責人 然而在上述的第1, 2 點提到的 reviewer 可能不會有時間幫你 review, 但應該藉由 cc 讓他們知道你此次的修改，若有幸也可以得到過去相關 developer 的建議，一定可以少走一些冤旺路～ 一些準則(how)這邊才是主體，以下整理 Google code review guideline 中 Author 建議注意的一些事項 (^u^) Terminology兩個術語，後續相關詞彙會使用縮寫代表~ CL: “changelist” 的縮寫, 代表希望能 merge 進 master branch 而正在 review 的 code block. 也被稱做 “change”, “patch”, “pr“ or “pull-request”. LGTM: “Looks Good to Me” 的縮寫，Reviewer 講出此言論時通常 PR 即可 Merge 進 Master. LG: “Looks Good” 的縮寫 Write Good CL DescriptionCL 的描述可以分為 First Line 以及剩餘的 Body 兩部分 First Line 應該盡量簡短的描述這次的 CL 做了哪些事情。 請使用完整的句子進行描述。 在最後請加上一行空行。 Body 請詳細的描述修改的內容 請詳述為何選用使用此種方式實作，使用其他方式的 pros, cons 若此次的解法只是短解，請在 CL 中提及，並且標注出短解的 code block, 並考慮開啟對應的 ticket 追蹤 若有背景知識需要讓 reviewer 知道請在 CL 中說明 (ex. bug numbers, benchmark results, link to design document) 考慮到未來會有開發者來參照此次修改，請補足 context 供未來讀者查閱時能更快瞭解修改內容 即便是很小的修改，也應該要有詳細的說明。 以下分別為一些好的例子以及不好的例子 不好的例子 “Fix build.” “Add patch.” “Moving code from A to B.” “Phase 1.” “Add convenience functions.” “kill weird URLs.” 上述的 CL 其實都有些模糊，單看描述會不知道在做什麼事情，Fix Build 的哪一個部分？ 新增了哪些 patch? 為什麼要把 code 從 A 處搬到 B 處？ 什麼東西的 phase 1? 等等…… 好的例子以下節錄自Author’s Guideline 範例 Functionality change Example: rpc: remove size limit on RPC server message freelist. Servers like FizzBuzz have very large messages and would benefit from reuse. Make the freelist larger, and add a goroutine that frees the freelist entries slowly over time, so that idle servers eventually release all freelist entries. Refactoring Example: Construct a Task with a TimeKeeper to use its TimeStr and Now methods. Add a Now method to Task, so the borglet() getter method can be removed (which was only used by OOMCandidate to call borglet’s Now method). This replaces the methods on Borglet that delegate to a TimeKeeper. Allowing Tasks to supply Now is a step toward eliminating the dependency on Borglet. Eventually, collaborators that depend on getting Now from the Task should be changed to use a TimeKeeper directly, but this has been an accommodation to refactoring in small steps. Continuing the long-range goal of refactoring the Borglet Hierarchy. Small CL that needs some context Example: Create a Python3 build rule for status.py. This allows consumers who are already using this as in Python3 to depend on a rule that is next to the original status build rule instead of somewhere in their own tree. It encourages new consumers to use Python3 if they can, instead of Python2, and significantly simplifies some automated build file refactoring tools being worked on currently. 最後在 送出 &amp; merge 前應該再次檢查 CL 的描述有符合本次的修改。 Small CLs為何應該讓程式碼維持多次小量的修改而不是一次大量的修改呢？ 除了比較好 Review 外也有眾多的原因，條列如下 因為涵蓋內容少，Reviewer 可以更快的進行 review 確保 reviewer 能看得更仔細，且思考的更全面 因為修改範圍小，bug 會更容易被找出 因為你只改了一點點，一有方向錯誤便能很快地察覺，反之若是花了一週弄一個很大範圍的 Code Change, 結果發現方向根本不對，這一週的時間就白白浪費掉了 QQ merge 若發生問題可以更快的 debug 因為修改範圍較小 小片段的程式碼更容易被 Reviewer 最佳化 避免 blocking, 在 review 的同時你可以繼續進行其他部分的 CL, 而不會被當前 review 的部分 block 住 發生錯誤時更容易 roll back 回穩定的版本 確保每次的 commit 可以成功 build 才能 merge 確保修改包含對應的 test code Refactor 的部分應該獨立開一條 branch 來處理，不要跟 bug fix / fetaure changes 放在同一次更動 How to Handle Reviewer Comments這部分比為面對 Reviewer comments 時的心態調整及相關建議 XD 不要帶著憤怒的情緒面對 reviewer 所留下的 Comments, Reviewer 也是為了提升 code 品質才花時間 review 並留下評論, 並竟應該沒有人想要故意把事情搞砸對吧？ 若 Reviewer 不理解您修改的 code, 大多時候你應該補充更多的上下文讓 reviewer 看懂你的 code，因為未來看這段 code 的讀者大多也會遇到一樣問題 若是對 reviewer 的 comment 不清楚，也應主動詢問 Reviwer 所提出的問題，確保雙方的認知一致 若堅決認為自己是正確的, reviewer 留下的 comment 存在著某些問題，請提供更多 context 給 reviewer，同時主動聯繫進行確認 若無法跟 Reviwer 達成共識，請參照 The Standard of Code Review 並確保最終達成共識 結論這篇大多就是集結 Google author guideline 中所提到的一些準則，若有漏掉重要的訊息非常歡迎留言讓我知道，看完後才發現原來送出一個 PR 裡面還存在著很多眉眉角角要注要，而不是簡短寫一下了事，也警惕自己未來的 PR 應該要更加注意，本身也還是小菜鳥還在學習的路上，未來有其他關於 Author 的心得也會一併更新在這篇文章中～ 感謝您的收看，下一篇預計會寫 Reviwer 需要著要的重點整理筆記。 歡迎點擊這邊 Google Code Review 全系列筆記瀏覽 code review guideline 全系列筆記文章 :) Reference https://google.github.io/eng-practices/ https://dev.to/saymy__name__/git-workflow-for-periodic-jenkins-builds-801 https://medium.com/@ryanyang1221/%E8%AE%93-google-%E6%95%99%E4%BD%A0-code-review-be251d4d81b4","link":"/20211129/google-code-review-1/"},{"title":"Google Code Review - Reviewer 篇","text":"如同上篇 Google Code Review - Author 篇 所述，此篇將整理 Reviewer 相關的筆記，因為 Reviewer 相關的內容較多，預計將分為三篇文章來記錄，一樣主要整理自 Google Code Review Guideline 的內容 ლ(・´ｪ`・ლ) The Standard of Code ReviewCode review 的目的是要確保 code 的品質不會隨著時間而越來越差，但若是力求完美而將 review 的時間拖得很長又會拖慢開發的效率，以下有一些 trade-off 準則必須考量。 首先開發人員應該在每次 CL (PR) 都確保 code 能得到提升，若是完全不對過去的 code 進行 refactor 或是修正，雖然會加速 review 的速度，但 codebase 就永遠不會得到提升，反之若是 reviewer 非常嚴格，將每次都力求完美，則 developer 會因為挫折而不敢對過往的 code 進行修正。 因此 Reviewer 應該以 code health 作為首要條件，確保每次 code merge 後不會造成影響，同時確保 codebase health 不會隨著時間而下降，這其實非常的困難，因為通常的情況下 codebase health 必定會隨著時間的推移而緩速下降，尤其是在有時間壓力時，為了趕在 deadline 前上線，會利用短解趕快讓功能上線等等的情況都會造成 codebase health 下降。 而 Google 提出的 review 準則如下 In general, reviewers should favor approving a CL once it is in a state where it definitely improves the overall code health of the system being worked on, even if the CL isn’t perfect. 上述的準則也是最高級的準則，任何情況下跟此準則有衝突，都應該以此準則為最高原則 No such thing as “perfect” code—there is only better code. 上述解釋了為何 Reviewer 不應該要求 Author 把每次 CL (PR) 都用得非常完美，相較而言 Reviewer 應該要確保的是持續的改進 continuous improvement、提升系統的可維護性、程式碼的可讀性、程式碼的可理解性，同時不應為了一些不完美而推遲發布時間。 Reviewer 可以留下任何的評論來幫助 author 一起提升 code 的品質，但若是一些無關緊要的建議可以在前面加上 Nit:, 我一開始看到 comment 中出現 nit 時也一頭霧水，後來才知道原來是 nitpick (吹毛求疵) 的縮寫 XD MentoringCode review 時可以盡量盡到教學相長的用意，留下你認為更好的 design、語法、設計原則、設計模式等等，reviewer 應該留下任何能夠幫助 developer 的評論，藉著共享知識來提高 codebase 的健康度，並且若只是出於提醒或是教育意義的評論，而不是一定要修改的評論可以如上述所說，在評論前面加上 nit:作為 prefix 來讓 developer 知道這則評論只是出於提醒的用意，並非一定要修正。 Principles 技術事實以及數據應該凌駕於個人的偏好之上 coding style 應該遵照既有的規則，若 reviewer 部分沒有既有的規則，可以透過 reviewer 跟 developer 討論而制定相關規則 對於系統設計或是架構相關的問題，不應單純使用個人偏好進行 review，而是應該透過一些共用的規則或是遵照某種設計模式來實作，若有多種解法則 development 應該提出來讓 reviewer 知道，並且說明選用該解法的原因以及跟其他解法相比的優點。 如果沒有規則可以遵照，則 reviewer 應該建議 developer 遵照當前的 codebase 中類似區塊的做法，並確保其不會造成 codebase 健康度下降。 Resolving Conflicts若在 review 的過程中發生意見的衝突，應該透過 The CL Author’s Guide 以及 Reviewer Guide 的準則來達成共識。 若還是無法達成共識應該擺脫 github comment 方式，藉由視訊軟體或是面對面來討論，藉此加速 review 的過程，同時要記得將討論結果記錄在 CL(PR) 的 comment 或是 description 上面，以此來讓後續的讀者知道過去討論的最終定案，以及選用此解法的原因。 然而經過上述的討論有時候還是會無法得到共識，此時應該藉助 team lead 或是 manager 甚至是邀請其他團隊中熟悉此功能開發者一起進來討論並衡量優劣，並尋求 team lead 或是 manager 做最終的決定。 歡迎點擊這邊 Google Code Review 全系列筆記瀏覽 code review guideline 全系列筆記文章 :) References https://google.github.io/eng-practices/review/reviewer/standard.html","link":"/20211207/google-code-review-2/"},{"title":"Google Code Review - Reviewer 篇 (2)","text":"本篇接續上篇 Google Code Review - Reviewer 篇 (1)為 reviewer 相關的第二篇，主要會敘述 code review 中應該要被 review 的事項以及詳細的細節，特殊情況下的應對等等，若有寫錯或是表達不清楚的地方，也請大大們鞭小力一點 (✪ω✪) Design 這部分是最重要的一環，必須確保 CL(PR) 整體的設計沒有問題，包含以下條列事項: 此次的變動是否合理? codebase 中是否已有相同的 library 可以直接呼叫使用? 此次的變化應該修改到共用的 library 中嗎? 這次的修改跟系統整合後會不會出問題? 現在是添加功能的好時機嗎? Functionality 這部份則是功能性相關的檢查 此次的變更是否符合開發者一開始的意圖? 這次的修改對 developer 以及 end-users 的影響? 大部分的情況開發者都會實作對應的 test case 去確保功能性正常，但 edge case 或者 corner case 可能會被忽略，這時候就需要借助 reviewer 來幫助做多一層的把關，concurrency problems、async、sync 等等的相關問題也可以在 review 的過程中再做多一層的把關，並試圖站在 user 的角度思考哪些操作可能會造成問題等等，並確保最後 deliver 的 code 為bug free 且高可讀性。 若牽扯到 UI 的變動，有時候無法直接從 CL (PR) 中看出修改造成的影響，此時可以請 developer Demo 給您看，確保修改合理。 另一類很難被發現的問題像是 parallel programming, deadlocks, 或是 race conditions 等等所造成的問題也很難在 review 時候被發現，必須多留意 Complexity 應該要避免 CL (PR) 太過複雜，應該讓邏輯盡量保持簡單，避免太多的語法糖，然而如何定義太複雜呢，文中給出了一個衡量標準 can’t be understood quickly by code readers. developers are likely to introduce bugs when they try to call or modify this code. 若出現以上兩種情況，則有可能代表你寫的太複雜了，通常若是開發者想要將 code 弄得非常 generic 而導致 over-engineering 的情況，或者添加了一些當前不必要的功能，這都會導致 code 變得複雜、可讀性差，Reviewer 應該對此提出問題，並且鼓勵 developer 先解決當前問題，而不是推測未來問題而將 code 過度模組化。 Tests Reviewer 應該要求 Developer 在 CL (PR) 中加上對應的測試，包含 unit test, integration test, or end-to-end test 等等，除非此次 CL (PR) 處在緊急的狀況，並且確保撰寫的測試有效，同時應該確保代碼發生變化導致邏輯發生問題時測試應該要失敗。 以下唯一些準則 : code run-time failed 時測試會如預期般的失敗嗎? 當邏輯改變時 是否會有 false postives 的情況產生? 測試中的 assert 是否有用，且覆蓋率足夠高? 是否洽當的在不同 function 間進行測試? test case 在未來也會需要被維護，也要注意複雜度不要過高。 Naming 是否有挑選洽當的命名? 應該在一定的長度內盡可能的讓讀者知道這個變數、方法、類別是用來做甚麼的。 Comments 這邊指的 comments 為 codebase 中所留下的 comments 而非 CL (PR) 討論中來回的 comments，怕會搞混先寫在前頭 XD developer 留下的英文 comment 是否足夠清楚的說明想要表達的事項? 是否有多餘的 comment 通常 comment 用來說明為何這段 code 會存在，而不應該用來說明這段程式碼在做甚麼事情，或者是選擇此作法的背後原因，大多時候應該藉由可讀性高的code 來讓讀者知道這段 code 在幹嘛，而不是利用額外的 comment 來詳述其邏輯（有些例外：regular expression 和 較難讀懂的演算法 通常還是會藉由 comment 來傳遞訊息）。 也可以看一下先前的 comments，找尋一些上下文的關係，有可能前人有留下 comments 來說明一些可能會遇到的問題等等。 Style 此部分為 coding style 的規範，通常每間公司都會有一套自己的 coding convention, 若沒有的話也可以參照 google 提出的 style guideline 使用 Nit: 引導開發者可以修正的變數、方法以及類別命名 不要因為個人的命名偏好而 block 住 code review 的流程 盡量不要在有其他目的 CL (PR) 同時進行變數命名的修改，應該另外發一個 CL (PR) 去修改變數，並且將變數修改的 CL (PR) merge 進去 master 後，將目前的 CL(PR) rebase master branch 後再繼續進行修改，這樣可以簡化 review 流程，且較不容易出錯 Consistency 若當前的 code review 跟既有的 style guideline 不一致應該怎麼做呢? 請以 style guideline 最為最高指南 有些時候，若有原本的 coding style 應該遵循既有的 coding style, 盡量與周圍的程式碼風格保持一致，但若遵照 style guideline 不會導致不一致性，則應該遵照指南 若沒有其他規則遵照，則應該保持與現有的規則一致 建議可添加 TODO 來記錄未來需要修正的 coding style 部分 Documentation 若 CL (PR) 的修正部分包含了 build, test, interact 或是 release process, 請一併檢查對應的文件是否更新，包含 READMEs, google doc, g3doc page 以及任何相關的文件，若文檔缺失也請補上對應文檔。 Every Line 請掃過 CL(PR) 中的每一行，且不要預設裡面是正確的，若因為 CL (PR) 太大而導致 review 需要較長的時間也應該讓 developer 知道，如果你看不懂 developer 寫的東西，那麼之後閱讀同一段程式碼的人也會遇到相同的問題，應該要求開發者說明該段程式碼的用意，並且討論是否有更簡易的作法方便未來閱讀。 若認為自己對該段程式碼不理解，或是需要更多的 context 補助，則應該請過去相關功能的開發者一起進行 review。 Exceptions如上面的例子，你可能是某方面的專家所以被要求協助 review，有時候你只被要求 review 其中一小段程式碼抑或是整體的架構，其餘的細節交由其他人負責，這時請在你 review 過的 part 留下對應的要求，並且在您認為達到標準後留下LGTM等 comment，讓開發者知道你 review 的部分沒有問題. Context 若使用 Github 作為 code review 工具會發現往往只會顯示包含修改內容的上下幾行相關程式碼，有時候你需要往上或這往下多看一些，確保你了解 context。 有時也需要更宏觀的去評斷這次的 CL (PR) 是否改善 codebase 的健康狀況? 還是會使整個系統變得更加複雜?是否需要更多的測試? 應該避免會使整個系統變得更加複雜的 CK(PR)，就跟堆雪球一樣，若每次 CL(PR) 都變得複雜一點點，則到最後整個 codebase 會變得超級複雜且難維護，因此在每次的 CL(PR) 中防止細小的複雜邏輯被引入到現有的 codebase 是很重要的。 Good Things 若在 CL(PR) 中看到一些很棒的東西，請告訴開發者，讓他們知道，雖然 review 常常都是為了避免錯誤，但如果 developer 做的很棒應該也要給予鼓勵跟讚賞，教學相長，作為相互學習的目的而言，告訴他們做對甚麼有時甚至比告訴他們做錯甚麼有價值~ Summary總結來說 Review 重點可以歸納為以下幾點，並請確保以下事項 Code 是否設計良好? 功能對使用者來說是否合理且完善? UI 的改變是否合理且美觀? Parallel programming 是否安全? Code 是否不會太複查，複雜度是否可以接受? 有沒有不必要的部分被一併提交? 對應的 Unit Test 有被補上嗎? Tests 是否測到所有應該被測試的情況? Naming 是否清楚? Comments 是否清楚且有用? 且請多使用 why 而不是 what 來撰寫 comments 對應的文件有被更新嗎? Coding style 符合規定嗎? 確保看過每一行或者被要求 review 的部分，多看 context 理解前因後果，確保 CL(PR) 提升 code health 並且對於 developer 做的好的部分給予鼓勵。 心得感謝看到這邊的大大們，這部分的內容比較龐大，原本想說用三篇文章的篇幅來筆記一下 Reviewer 的部分，看起來應該失算了，為了避免文章過長，應該會超過三篇文章 QAQ 歡迎點擊這邊 Google Code Review 全系列筆記瀏覽 code review guideline 全系列筆記文章 :)","link":"/20211211/google-code-review-3/"},{"title":"Google Code Review - Reviewer 篇 (3)","text":"接續上篇 Google Code Review - Reviewer 篇 (2)本篇為 reviewer 相關的第三篇，上篇為 reviewer 在 code review 中應該要注意的細節，而本篇主要會筆記一下 Reviewer 的 review 順序建議 ( • ̀ω•́ ) Summary從上一篇我們知道了作為 reviewer 時應該要 review 的細節, 然而應該要如何進行才能比較有效率的 review 多個檔案呢? 文中建議的 Review 順序 CL (PR) 是否合理? developer 寫的 Pull-Request description 清楚嗎? 先審查 CL(PR) 中最重要的部分，並且確定整體的設計是良好的。 查看剩餘的 CL(PR) 部分。 Step One: Take a broad view of the change參照description中的建議檢查 Description，並且確保此次的 CL(PR) 合理，一旦發現 CL(PR) 不符合要求請立馬通知 develpoer, 並告知原因, 藉此避免 developer 浪費時間進行不必要的開發，必且建議或跟開發者討論後續應該進行的方向，也節省團隊的時間 當發現developer CL 出現了不合乎預期的狀況，文中給出的範例回覆如下 Looks like you put some good work into this, thanks! However, we’re actually going in the direction of removing the FooWidget system that you’re modifying here, and so we don’t want to make any new modifications to it right now. How about instead you refactor our new BarWidget class?` 從上述的範例我們禮貌的拒絕了此次的 CL (PR), 同時也提供了 developer 對應應該努力的方向，文中一直提到了 禮貌 &amp; 尊重 的重要性，畢竟不會有人希望自己的努力被說的一無是處對吧? 若 CL (PR) 中出現了太多不預期的狀況，可能必須考慮修正 Code Review 流程，與其在需求不明確時就實作，更應該在需求明確且團隊成員認知相同時再進行實作，這樣可以避免 developer 寫了一堆 code 結果發現不符合需求，得要全部砍掉重練的情況也就是大家常說的預防勝於治療 (´ω)人(´ω) Step Two: Examine the main parts of the CL(PR)找出 CL(PR) 中主要的部分優先進行 review, 通常會是 CL(PR) 中改動最多的部分，若改動的部分太多，難以找到主要的 CL(PR) 部分，可以求助 developer 詢問那邊是重點的部分應該先被 review, 並且可以要求 developer 將一個太大難以 review 的 CL(PR) 依照功能或是改動部分切為數個小一點的 CL(PR) 以方便 review. 若有看到 CL(PR) 中有明顯的錯誤，即便還有許多剩餘的部分還未 review,，應該先留下 comment 讓 developer 知道，甚至如果您先進行review 還有可能是在浪費時間，因為後續的部分有很大的機率會跟著修改。 以下為兩個當主要設計出現問題時您應該要立刻提出的主要的原因: 由於開發者可能基於此 CL(PR) 繼續往下開發，但設計問題可能導致後續的 CL(PR) 需要一併做修改，因此為了幫助 developer 節省時間，應該要先告知他們有問題的部分，避免後續 CL(PR) 需要全部修改一輪。 主要的設計問題修改會比小地方的修正需要花費更多的時間，而開發往往都會有壓期限，為了趕上在期限內完成，請盡速通知 developer 主要部分的問題，讓他們有更多的時間進行修改並提高程式碼的品質。 Step Three: Look through the rest of the CL in an appropriate sequence當確認設計沒有問題且完成了主要部分的 review 後，接續進行剩餘檔案的 review，請確保您的對改動部分完全理解，有時候也可以從 test 下手，先看 test 的測項對於 review 也有一定的幫助，可以從 test 中去推斷功能的預期的邏輯為何。歡迎點擊這邊 Google Code Review 全系列筆記瀏覽 code review guideline 全系列筆記文章 :)","link":"/20211214/google-code-review-4/"},{"title":"Google Code Review - Reviewer 篇 (4)","text":"這篇主要整理如何加速 code review 的速度, 以及 code review 速度對於整體開發流程的影響，為針對 reviewer 系列的第四篇文章，為 google code review 筆記系列的的六篇文章。 Why Should Code Reviews Be Fast?應該優化整體團隊開發產品的效率，並非單獨開發者的開發效率。 code review 速度很慢的話可能會引發的問題 整體團隊開發速度下降 開發者抗議 code review 的流程若 reviewer 幾個天或是幾周才 review 一次，且每次都要求更改很多地方，這會讓 developer 很沮喪，進而降低開發的速率，且大多數的對於 code review process 的抱怨都可以透過加速 review process 來得到解決。 code health 被影響緩慢的 code review 會影響 code 的 cleanups, refactorings 以及一些對現有系統的改進。同時也會增加 developer 的壓力。 How Fast Should Code Reviews Be? 若您不是在需要很重要的任務上，你都應該優先去 review CL(PR) 一個工作天是最長可以被忍受的時間(第二天早上的第一件事) 一天應該對一個CL(PR)進行多次review直到被合併進repo Speed vs. Interruption若當前正在寫 code 則請繼續完成，不要被 code review 打斷，研究表明 developer 在被中斷後可能需要很長時間才能恢復並進入狀態，因此若在開發過程中，請先完成手邊的工作或使其進行到一段落在進行別人請求的 code review, 就跟電腦 CPU一樣，做 context switch 多少都會浪費掉時間對吧?! Fast Responses即便 code reivew process 可能拖很長的時間，還是必須盡量快速的響應 developer 所提出的 code review 請求，個人的快速回應可以大大降低 review 時間拖很長的挫敗感。 若你手邊有很忙的事情，可以先通知 developer 讓他知道大約何時 code review 會完成，或者先留下一些比較 critical 的 comment 讓 developer 可以先進行修正，抑或是請對應的人先幫忙 review。 LGTM 表示已經可以達到 merge master 的標準，此時 developer 可以選擇繼續把細微的問題修正或是直接 merge。 Cross-Time-Zone Reviews因為疫情的關係越來越多 remote 以及跨國跨時區的工作型態，盡量在 developer 時區工作時間回覆 comment, 假使 developer 已經回到家, 確保在他們第二天回到辦公室之前完成您的 review &amp; comment。 LGTM With Comments為了加速流程，以下兩種情況可以先留下 LGTM/Approval 的評論，即便還有地方要修正: reviewer 確信 developer 會適當地解決審閱者的所有剩餘評論 剩下的修改很小，不一定需要修改只是 reviewer 給予的建議 由於跨時區的關係，有時等待一整天只是為了得到 Approval/LGTM 確實會浪費掉不少時間，請多採用 LGTM with Commens 方式讓 developer 知道哪些部份修正後測過確定沒有問題就可以自行合併了。 Large CLs太大的 CL(PR) 很難 review, 且通常會拖慢整個 review 流程。可以請 developer 依照不同功能切成小一點的 CL(PR)。 若無法將CL(PR) 切小，可以採取上述的做法，先快速看過點出問題請 developer 先進行修改，並在手邊事情告一段落時再進行完整 reveiw, 作為 reviewer 主要的目標之一為協助 developer 可以快速得到回應並修正改善 codebase quality. Code Review Improvements Over Time若你按照上述的準則進行 code review, 應該能感覺到 review 的流程越來越快，同時 developer 也會學習到哪邊是應該要避免的錯誤，慢慢的 developer 的 CL(PR) 需要更動的地方也會越來越少，reviewer 盡量的快速回應 CL(PR)，達成正向的循環。 Emergencies若有非常緊急的問題需要修正，則可還是必須要走過完整的 review process, 但可以 code quality 要求的寬鬆一些，以下為 Emgergency 的定義。 Conclusion感謝您的收看，此為第六篇 google code review 的筆記，應該還剩下最後兩篇 XD，下一篇將會講述 Review Comments 應該如何撰寫~可以點擊這邊 Google Code Review 全系列筆記瀏覽 code review guideline 全系列筆記文章 :)","link":"/20211214/google-code-review-5/"},{"title":"Google Code Review - Reviewer 篇 (5)","text":"正如封面的照片一樣，code reviewer 的氛圍應該是要開心愉悅的，而不是針鋒相對，接續上篇 Google Code Review - Reviewer 篇 (4)，本篇住要講述 reviewer 的 comments 應該如何撰寫，以及一些應該注意的事項 ლ(╹◡╹ლ) Summary 友善交流 解釋您的看法 在點出問題以及給予問題解答讓開發者決定兩者之間找到平衡 鼓勵開發者簡化代碼或是添加註解在code中，而不是單純向您解釋 Courtesy尊重&amp;禮貌為code review 中很重要的事情，且評論請針對 code 而不是針對 developer 舉例如下: Bad: “Why did you use threads here when there’s obviously no benefit to be gained from concurrency?” Good: “The concurrency model here is adding complexity to the system without any actual performance benefit that I can see. Because there’s no performance benefit, it’s best for this code to be single-threaded instead of using multiple threads.” Explain Why解釋您留下 comment 的原因，讓 developer 了解 為何 你會留下comment, 並不是所有地方都需要留下 comments &amp; 原因，而是針對 developer 可能不理解的地方留下原因，例如這樣做符合 desing pattern, 這樣做可能有哪些 side effect, 或是這樣未來比較好維護等等的原因。 Giving Guidance一般而言修正 CL(PR) 為 developer 的責任，而非 reviewer 的責任，reviewer 沒有義務去做細節的 design 或是直接幫 developer 寫 code。 但這並不代表 review 沒有幫助，reviewer 應該在指出問題點以及直接指導間取得平衡，單純指出問題點讓 developer 做決定可以幫助 developer 學習，同時對 reviewer 也會比較輕鬆，同時因為 developer 對自己寫的 code 比較清楚，通常 reviewer 點出問題點讓 developer 做決定也會比直接由 reviewer 直接給出解法效果要來的好。 不只是問題應該被點出，若 reviewer 看到 CL(PR) 中有很棒的地方應該也要點出來讓 developer 知道，。 舉例而言: 當看到 developer 清理原本雜亂的 algorithm, 提升 test coverage, 或者任何你從 reviewe 過程中學習到的事情，也都應該留下評論藉此鼓勵 developer 讓 developer 在未來繼續保持良好的實踐。 Accepting Explanations若 reviewer 要求開發者解釋一段不清楚的 code, 通常 developer 會選擇直接重寫讓那段 code 變得比較易讀，有些時候比起整段重寫加一些註解可能會更適當，當然前題是原本的 code 沒有過於複雜。 若只在 code review tool (Github) 留下 comment 對未來的 developer 沒有太大的幫助(除非他跑來翻 PR 看過去的討論串才能知道一些 context)，應優先考慮讓 code 變得易讀，或是在一些關鍵的地方加上註解。 Conclusion感謝您的收看，這篇主要筆記了 reviewer 的 comments 應該如何撰寫，以及那些東西應該被 comments，接下來就是最後一篇了，會講述一些在 code review 中 comment 的來回應對 :) 歡迎點擊這邊 Google Code Review 全系列筆記瀏覽 code review guideline 全系列筆記文章 :)","link":"/20211222/google-code-review-6/"},{"title":"Google Code Review - Reviewer 篇 (6)","text":"code review 中 developer 以及 reviewer 意見不和是常常發生的事情，有時 developer 會不同意 reviewer 的觀點，有時候 developer 會覺得 reviewer 太過嚴格，這時候應該要如何解決呢? 這篇筆記會記錄 google code review 中給出的一些建議 (´◉‿◉｀) Who is right?通常 developer 相比 reviewer 而言會更熟悉自己修改的 code, 若 developer 不同意您的建議，需要跟 developer 釐清，若 developer 是對的必須必須讓他們知道，並關閉提出的問題以及修改建議。 但若您很確定您的評論是正確的，應該詳細解釋讓 developer 知道，並且禮的指出怎麼做可以提升 code quality, 有時候一個建議需要經過幾輪的討論，切記要保持禮貌，並且讓 developer 知道自己提出的意見有被收到，只是有其他更好的建議作法可以採用。 Upsetting Developers作為 reviewer 可能會擔心過度嚴格的標準會導致 developer 不開心，有時候確實會使 developer 感到沮喪，但通常只是短暫的，之後 developer 更有可能會感謝您幫他們提高 code quality, 若是出於好意且用詞禮貌的提醒基本上都不會讓 developer 不開心。 Cleaning It Up Later盡量避免之後開另一個 CL 修正一些相關的錯誤，可以的話盡量把在 PR 中被點出的錯誤修正，如果需要修改的範圍太大一定要開另外一個 CL(PR) 來修正的話，一定要記得開一張對應的 Ticket 並且寫好 description 並且 assign 給自己，並且在 Code 中加上對應的 TO-DO comment，才不會問題越滾越多然後都忘記要修正 ( •́ω•̩̥̀ ) General Complaints About Strictness如果過去 code review 相當鬆散，突然變的嚴格，會導致 developer 抱怨。加快 review 的速度會讓情況緩解。 有時抱怨的情況可能會持續長達幾個月，但隨著時間推進 developer 會逐漸了解的嚴格 code review 所帶來的效益，可能是 code 變得易讀或是 bug 變少等等之類的效益。 Resolving Conflicts若遵照上面提出的準則還是無法解決，請參閱The Standard of Code Review解決衝突。 Conclusion感謝您的收看，到目前為止為 google code review 的完整筆記, overview 1 篇, author(developer) 1篇, reviewer 5 篇，歡迎點擊這邊 Google Code Review 全系列筆記瀏覽 code review guideline 全系列筆記文章 :)","link":"/20211225/google-code-review-7/"},{"title":"幫網站畫圖標","text":"幫網站畫圖標最近在瀏覽網站時突然覺得netflix 的圖標讓人印象深刻，突然想到自己的網站上一直沒有圖標，於是決定來幫網站加個圖標ＸＤ netflix 圖標 試畫了幾版第一版 第一版 網站利用英文名稱 Mike 的第一個英文字母 M 為主體(事實上是因為沒有美術天分不知道怎麼畫XD)，第一版畫完後總覺得哪裡不太對近，觀察完後發現現在許多圖標設計好像都是將背景色圖滿，而圖標用白色的字體，於是就照著Yahoo, Mozilla 的樣式進行一下修正。 第二版 第二版 因為第一版顏色有點太刺眼於是修正了顏色，並且將字體修細，但是還是覺得有點怪怪的。 第三版 第三版 參考了FlatColor 網站的顏色，挑選了一個比較好看的顏色取代~ 第四版 第四版 後來想想 M 好像有點太常見，所以就將字體 90 度旋轉變成 Sigma ，隨然沒有實質上的意義，但感覺會比較好記，而且看起來好像比較炫炮，美觀上好像也比較好一些!? 然後配合黑白的網站顏色也把圖標改成暗色系為底 XD 結論美術設計真D好深奧 QAQ","link":"/20200802/icon_design/"},{"title":"花十分鐘打造好用的 termianl (iterm2 + zsh + oh-my-zsh + powerlevel10k)","text":"簡單花 10 分鐘打造好用 mac terminal 設定最近因為有電腦重新設定的需求, 而重灌或是使用新電腦的第一件事情通常都會是安裝 terminal 環境, 於是就順手紀錄一下 homebrew, iterm2, zsh 的設定步驟,順便附上 vscode 需要進行對應的設定步驟～ 安裝還境: MacOS: Big Sur (11.4) Install homebrew Mac 使用這必裝的套件管理工具 1$ /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; 若安裝時卡在 download command line tools for xcode 只須照著以下步驟更新即可 system preferences → Software Update → More info 勾選 xcode tool, 並更新，安裝完成後重新執行 homebrew 安裝指令即可 Install iterm2 好用的 Terminal 1$ brew cask install iterm2 Install zsh Z shell是一款可用作互動式登入的shell及指令碼編寫的命令直譯器。Zsh對Bourne shell做出了大量改進，同時加入了Bash、ksh及tcsh的某些功能。 (擷取自 wiki) 檢查是否有 zsh, 新版的 MacOS 有內建 zsh 若已經安裝過 zsh 可以跳過此步驟 12345# check zsh installation status $ which zsh# modify default shell to zsh.$ chsh -s $(which zsh) Install oh-my-zsh 提供 zsh 配置, 主題, 插件 管理功能 1sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; Install zsh theme: powerlevel10k 幫妳的 zsh 換上美觀的主題 1234567891011# download zsh theme: powerlevel10k$ git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k# update zsh theme $ vim ~/.zshrc# update configZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;# refresh terminal $ exec $SHELL 此時應該會請您進行一些基本外觀設定，依照個人喜好選擇即可 到這裡就完成基本的設定了~ Update VSCode Config (Optional)若是 VSCode 使用者此時應該會發現當中的 terminal 顯示會怪怪的，必須到 VSCode 中進行簡單的調整，以下擷取自: https://github.com/romkatv/powerlevel10k/issues/671 的分享 假設使用 powerlevel10k 預設的字體只需按照下方設定即可正常顯示 Open Settings in Visual Studio Code. On PC: press Ctrl+, On Mac: press Cmd +, Enter terminal.integrated.fontFamily in the search box at the top of Settings tab and set the value below to MesloLGS NF. 完成設定後就可以看見 vscode 的 terminal 正常顯示了~ 若使用其他的字體必須先下載字體再進行設定可以參照文章的分享設定。 感謝收看 Reference https://stackoverflow.com/questions/64310320/difference-between-iterm2-zsh-and-oh-my-zsh https://www.onejar99.com/terminal-iterm2-zsh-powerlevel10k/#Step_2_zsh","link":"/20211018/mac-iterm2-homebrew-zsh-config/"},{"title":"解題常用排序演算法 (附上動圖)","text":"排序演算法是許多題目的基礎概念，解題時有許多技巧也是由排序演算法所衍生，使用 python3 實作，並且附上網路的動態圖片。 簡單排序 - O( N^2 ) Bubble Sort1234567# 兩兩相比, 將大的放到後面， 每一回合會把一個key 放到正確位置(最後方的key)def bubble_sort(nums): l = len(nums) for i in range(l): for j in range(i-1): if nums[i] &lt; nums[j]: nums[i] , nums[j] = nums[j], nums[i] GIF 圖片來源： https://wangonya.com/blog/js-sort-1/ Insertion Sortclass:'lineNo'12345678# 從 idx 0 開始一路往下走，並每輪把當前 pivot 插入先前已排序的數組中的正確位置def insert_sort(nums): for i in range(len(nums)): pos, cur = i, nums[i] while pos &gt; 0 and nums[pos-1] &gt; cur: nums[pos] = nums[pos-1] # move one-step forward pos -= 1 nums[pos] = cur GIF 圖片來源 : https://dev.to/wangonya/sorting-algorithms-with-javascript-part-1-4aca Selection Sort123456789# 每次當前回合最小的和最左邊未排序的數字(index: i)交換def selection_sort(nums): for i in range(len(nums)): pivot = i for j in range(i+1,len(nums)): if nums[j] &lt; nums[pivot]: pivot = j nums[i-1],nums[pivot] = nums[pivot] , nums[i-1] GIF 圖片來源 : https://codepumpkin.com/selection-sort-algorithms/ 高等排序 - O( NLogN ) Merge Sort12345678910111213141516# divide and conqure 技巧, 每次把串列對半切，並且串列長度&lt;=1 時,開始 mergedef merge_sort(nums): if len(nums) &lt;= 1 : return nums m = len(nums)//2 l = merge_sort(nums[:m]) r = merge_sort(nums[m:]) res = [] while l and r : if l[0] &lt; r[0]: res.append(l.pop(0)) else: res.append(r.pop(0)) res += l or r return res GIF 圖片來源 : https://codepumpkin.com/selection-sort-algorithms/ Quick Sort123456789101112131415161718192021# Lomuto Version # 每一 run 將第最後一個元素當比較值 pivot, # 用 idx 紀錄pivot 應該放的位置# 並且依序 &lt;= pivot 的放右邊, &gt; pivot 的放左邊def quick_sort(nums): if len(nums) &lt;= 1: return nums idx = 0 pivot = nums[-1] for i in range(len(nums)-1): if nums[i] &lt;= pivot : nums[i] , nums[idx] = nums[idx] , nums[i] idx += 1 nums[idx] , nums[-1] = nums[-1] ,nums[idx] l = quick_sort(nums[:idx]) r = quick_sort(nums[idx+1:]) return l + [nums[idx]] + r GIF 圖片來源 : https://www.codesdope.com/course/algorithms-quicksort/ Merge sort 以及 Quick sort 部份為了簡潔所以把 divide, conquer 兩部份寫在一起, 而quick sort 用的是Lomuto 的版本(私心認為比較好理解XD),Hoare 的版本可以參考這裡 ,謝謝收看(ﾉ&gt;ω&lt;)ﾉ ～～","link":"/20191120/sort_gif/"},{"title":"System Design - Twitter","text":"本篇文章為針對 花花醬 Youtebe 所講述的內容進行筆記，一切都還是以影片中的內容為主，會知道此頻道是因為在碩班畢業前，找工作刷題時在網路上搜尋解題講解時所發現。 最近因緣際會下發現除了 leetcode 演算法外，頻道內也開始有一些系統設計相關的內容，內容都講得非常好且多半都配合圖解來模擬運行時的邏輯，有需要的大大們可以去上面挖寶 XD Interview Signals Work Solution Analysis and communication Tradeoff Pros/Cons Knowledge Base Overview Clarify the requirements Capacity Estimation System APIs High-level System Design Data Storage Scalability 1. Clarify the requirement (系統規模) Requirements Traffic size Nobody expect you to design a complete system in 30-45 mins Discuss the functionnalities, align with interviewers on components to focus. Type 1 : Functional Requirement Type 2 : Non-Functional Requirement 2. Capacity Estimation (規模估算) Storage Estimate Bandwidth Estimate 藉由 Bandwidth 分析可以找出 bottleneck, 進而改善 scalability 3. System APIs pageSize 用於判斷手機或是電腦螢幕大小，藉以返回對應需要的 tweets 數量，藉以節省 bandwidth, 或者優化用戶體驗。 pageToken 用來實現翻頁的功能 4. High-level System Design User TimeLine User create tweets 時 應該考慮把追蹤人數多的用戶(Elon musk)的 tweets 寫入 Cache Home Timeline 避免 TimeLine 需要每次計算，可在 cache 中預先存好每次要展示給用戶看的 Timeline 何時應該更新用戶看到的 Home Timeline? 用戶發布 Tweet 時候來更新，Tweet Writer 儲存 Tweet 時一併更新 followers 在 cache 中的 Timeline Cache. Home Timeline (Naive) (Pull) Home Timeline (fan out on write) (Push) 由於 write latency 對用戶而言比較不重要，可使用 async 方式慢慢做, 每個 follower 被更新的時間並不是那麼重要。 Home Timeline (fan out on write) (cont’d) Fan out 方式有哪些侷限性? 舉例而言 Taylor swift 可能有 87.8 million followers, 若使用 fan out 的方式則會導致需要一次更新87.8 million 筆資料, 然而某些可能是 inactive user, 某些可能是假帳號, 對於粉絲數量大於 10k 的使用者使用 fan out 的方式顯然效率會不好。 使用 Hybrid 方式作為解法: Non-hot users fan out on write (push). do not fanout on non-active uses. Hot users fan in on read (pull): read during timeline request from tweets cache, and aggregate with results from non-hot users. 5. Data Storage SQL Table Database 6. Scalability 找出 bottlenecks 探討解法，以及每個解法的 trade-off Data Sharding : 如何把 data store 在不同的 server 上, 使得 read 時可以更 stable Load Balancing: 大量的用戶 request 如何把它 assign 到不同的 server 上, 使得每個 server 的負載達到平衡。包含 user 跟 application 之間，以及 application server 跟 cache server 之間抑或是 application server 跟 database 之間。 Data Caching: 解決 read haevy 問題。 Data sharding 由於資料量過大，全部存在一章表是不可行的，應該將其切成一個一個的小塊(shard), 可以把一個個的 shard 存儲在不同的服務器上面，藉此解決 horizontal scaling 問題，只要機器增加的速度大於 tweet 產生的速度，則理論上可以無限地擴展下去。 Data Sharding (Shard by creation Time) 利用 timestamp 進行 shard Pros 可以簡易的用時間得到 tweet 的儲存位置, 可降低不必要的 task 數量 Cons Hot/Cold data 問題，twitter 很重時效性，最近被創建的 table tweet read / write 的量會遠大於過去的 tweet 的 table, 時間久遠的 tweet 讀到的機率也會很低 (資源浪費)。 Data Sharding (Shard by hash userId) 利用 userId 進行 hash 並取 mod，最後儲存到對應的 shard Pros 簡單 一個用戶的數據都儲存在同一個 shard。 Cons Home tineline 還是要 query 很多的 shard. 有可能有數據太大沒有辦法放進一個 shard 的情況。 Hot user 導致該 shard 會負載太重，會間接影響 availablity. Data Sharding (Shard by hash tweetId)![](Untitled 16.png) 利用 tweet id 進行 shard Pros 即便是 hot user, 還是會因為 tweetId 的緣故平均分配到不同的 shard. 高可用性 Cons generate user/home timeline 時候一樣需要 query all shard (可以透過 cache 來解) Caching 由於 social network application 的特性， heavy read traffic, 要產生像是 home timeline 這種頁面因為要大量的 query 會比較慢，因此使用 cache 來解決，將 hot query 儲存在 cache 中，避免大量的對 DB 進行 hit。 cache 中存甚麼? key: userId, value : tweets id list 只需要存最近的幾千條, 其他放 DB tweetId → tweet content 的 mapping table Topic 應該使用 LRU, LFU 抑或是其他的 caching policy ? cahce 應該如何做 sharding capacity 以及 performance 結論 更完整的設計細節可以參考這個 Repository ，當中有許多經典面試題目:) Reference https://www.youtube.com/channel/UC5xDNEcvb1vgw3lE21Ack2Q https://github.com/donnemartin/system-design-primer/blob/master/solutions/system_design/twitter/README-zh-Hans.md","link":"/20220109/system-design-1/"},{"title":"Vespa ai 筆記 (一)","text":"Vespa ai 筆記 (一) Vespa 是什麼一般講到vespa 通常第一個聯想到的往往是某個機車品牌XD，然而除了機車品牌外它同時也是一個開源的搜索引擎，Vespa 由 Yahoo! ( verizon media ) 於 2017年9月發布， Vespa 用於對海量數據集進行低延遲計算的引擎，它負責存儲和索引數據資料。同時 Vespa 中也提供了: Indexing, Searching, Ranking, Grouping，等等許多自定義的擴展功能。 來看看官方的描述： 第一次看到是不是會有種不明覺厲的感覺XD 而也因為這些特性我們常常利用vespa 來建立: 搜尋引擎 個人化推薦系統 需要 Realtime 數據顯示的地圖，標籤，圖形…等等 而 Vespa 團隊因為近期因為 CORD-19 (新型冠壯肺炎)的快速傳染，利用Allen Institute for AI 所釋出的公開資料集，建立了新型冠壯病毒的搜尋網站，而該專案也是完全開源的(點這裡查看)。 Vespa 的索引概念以及運作原理Vespa 的主要架構圖如下 主要可以分為三塊 Stateless Container Cluster Content Cluster Admin and config clusters Stateless Container Cluster為架構圖中藍色的部份，主要負責 Document 的 get, put, update, remove 等操作，當有外部的 request 打進來時，Container cluster 會自動將操作送到對應的 content node 中進行。自定義的排序方法、文件處理、其他功能也在此 cluster 中進行 。 Content Cluster相較於前者，Content Cluster 負責的業務則相對簡單，負責資料的儲存，會將同一份資料複製到多個節點上，以及執行從 Container Cluster 所要求的操作，當所有 Cluster 中對應的節點執行完操作後，content Cluster 會自動匯總結果。 而該 cluster 會自動平衡節點中的數據量，並且維持 Redundancy 已提高容錯性，針對壞掉的節點自動進行故障轉移，保證高可用行並自動恢復。 Admin and config clusters除了上述兩種外還有第三種主要負責一些節點設定等等。 利用 Vespa 動手實做一個簡單的搜尋引擎吧！！介紹利用 WorldPress 的資料集建立一個部落格文章推薦系統，實做用戶文章搜尋，以及個人文章推薦的功能，而該文章由Vespa Team 所發布可以點這裡查看原文。 Prerequisites Docker Git OS : macOS or Linux(Ubuntu, CentOS …..) Architecture: x86_64 Minimum 6GB memory dedicated to Docker (the default is 2GB on Macs) - 10G for monitoring section. Datasetkaggle dataset Post 的基本屬性| Column | Description || —————– |:———————– || post_id | unique numerical id identifying the blog post || date_gmt | string representing date of blog post creation in GMT format yyyy-mm-dd hh:mm:ss || author | unique numerical id identifying the author of the blog post || url | blog post URL|| title | blog post title|| blog | unique numerical id identifying the blog that the blog post belongs to|| tags | array of strings representing the tags of the blog posts|| content | body text of the blog post, in html format|| categories | array of strings representing the categories the blog post was assigned to| Requirements 在開始前必須要先建立環境，利用官方所提供的 docker image 可以快速的把環境建好～ 建立 &amp; 切換 工作目錄 12$ mkdir blog$ cd blog 建立 Docker 環境 123$ docker run -m 10G --detach --name vespa --hostname vespa-tutorial \\ --privileged --volume `pwd`:/app \\ --publish 8080:8080 --publish 19092:19092 vespaengine/vespa 若上述步驟遇到 docker memory limit 解法參考 link 確認 server 建立成功，會得到 200 OK 的 response 1$ docker exec vespa bash -c 'curl -s --head http://localhost:19071/ApplicationStatus' Clone Git Repo ，會利用當中的 script 產生 data 1$ git clone --depth 1 https://github.com/vespa-engine/sample-apps.git 下載Feeding 時所需的資料點這裡 至此恭喜您已經完成所有的環境建立步驟~ 加入設定檔 加入必要的設定檔 在剛剛空的資料夾中建立對應資料夾 application 1$ mkdir application 在 application 目錄中建立 services.xml，用來定義需要多少 server 的基本配置。 123456789101112131415161718192021222324252627282930&lt;?xml version='1.0' encoding='UTF-8'?&gt;&lt;services version=&quot;1.0&quot;&gt; &lt;container id=&quot;default&quot; version=&quot;1.0&quot;&gt; &lt;search&gt;&lt;/search&gt; &lt;document-api&gt;&lt;/document-api&gt; &lt;nodes&gt; &lt;node hostalias=&quot;node1&quot;&gt;&lt;/node&gt; &lt;/nodes&gt; &lt;/container&gt; &lt;content id=&quot;blog_post&quot; version=&quot;1.0&quot;&gt; &lt;redundancy&gt;1&lt;/redundancy&gt; &lt;search&gt; &lt;visibility-delay&gt;1.0&lt;/visibility-delay&gt; &lt;/search&gt; &lt;documents&gt; &lt;document mode=&quot;index&quot; type=&quot;blog_post&quot;&gt;&lt;/document&gt; &lt;/documents&gt; &lt;nodes&gt; &lt;node hostalias=&quot;node1&quot; distribution-key=&quot;0&quot;&gt;&lt;/node&gt; &lt;/nodes&gt; &lt;engine&gt; &lt;proton&gt; &lt;searchable-copies&gt;1&lt;/searchable-copies&gt; &lt;/proton&gt; &lt;/engine&gt; &lt;/content&gt;&lt;/services&gt; 用以定義上述架構圖中的 container cluster 設定 query endpoint ， 預設為 8080 port 設定 Feeding 文件的 endpoint 設定該 cluster 中需要多少節點 設定 content cluster 設定需要多少份複製文件以供節點錯誤時進行自動回復 指定 node 中的 document schema (sd 檔) 設定 cluster 中的 node 在 application 目錄中建立 hosts.xml，由於我們使用docker 在 local host 建立，只需要定義為如下即可。 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;&lt;hosts&gt; &lt;host name=&quot;localhost&quot;&gt; &lt;alias&gt;node1&lt;/alias&gt; &lt;/host&gt;&lt;/hosts&gt; 建立 application 目錄中建立 blog 要被搜尋的文件的 blog_post.sd ， 路徑 application/schemas/blog_post.sd 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748schema blog_post { document blog_post { field date_gmt type string { indexing: summary } field language type string { indexing: summary } field author type string { indexing: summary } field url type string { indexing: summary } field title type string { indexing: summary | index } field blog type string { indexing: summary } field post_id type string { indexing: summary } field tags type array&lt;string&gt; { indexing: summary } field blogname type string { indexing: summary } field content type string { indexing: summary | index } field categories type array&lt;string&gt; { indexing: summary } field date type int { indexing: summary | attribute } } fieldset default { fields: title, content } rank-profile post inherits default { first-phase { expression:nativeRank(title, content) } }} 當中 indexing 設定了vespa 會如何 indexing 該欄位 index : 對該欄位界建立 index 供搜尋時使用 attribute : 會將該欄位存在 memory 中，供排序、搜尋、合併時使用 summary : 定義使否出現在 summary 中，搜尋的結果是否會將該欄位顯示 建立完成後application 目錄下應該會長這樣 部屬應用到本機端12$ docker exec vespa bash -c '/opt/vespa/bin/vespa-deploy prepare /app/application &amp;&amp; \\ /opt/vespa/bin/vespa-deploy activate' 接著去打 http://localhost:8080/ApplicationStatus 就能看到一些基本資訊，說明應用已經成功部屬。 Feeding Data 接著我們將必要的資料 Feeding 到搜尋引擎中。 將剛剛下載的文檔解壓縮 擷取前10000 筆資料(也可以跳過這步驟使用整個dataset XD) ，並利用script 轉成 對應的 JSON 格式，以降低處理時間。 12$ head -10000 trainPosts.json &gt; trainPostsSmall.json$ python sample-apps/blog-tutorial-shared/src/python/parse.py trainPostsSmall.json &gt; tutorial_feed.json 利用 Vespa Team 提供的 JAVA Feeding API 將資料打進 Vespa 搜尋引擎中 12$ docker exec vespa bash -c 'java -jar /opt/vespa/lib/jars/vespa-http-client-jar-with-dependencies.jar \\ --verbose --file /app/tutorial_feed.json --host localhost --port 8080' 利用 Metrics API 確認 feeding 結果，若 Feeding 成功則會看見對應的 feeding 筆數。 1$ curl -s &quot;http://localhost:19092/metrics/v1/values&quot; | tr &quot;,&quot; &quot;\\n&quot; | grep content.proton.documentdb.documents.active 現在我們可以用對應的 Doc ID 去要資料。 1$ curl -s 'http://localhost:8080/document/v1/blog-search/blog_post/docid/507823' | json_pp Query 用自訂的 query 去搜尋引擎拉東西 通常 vespa 利用 HTTP GET, HTTP POST 的 request 會長得像下面格式。 1&lt;host:port&gt;/&lt;search&gt;?&lt;yql=value1&gt;&amp;&lt;param2=value2&gt;... 我們可以用以下兩種形式的Query 去要資料，而使用的為YQL 的Query 語法 。 12curl -s -H &quot;Content-Type: application/json&quot; --data '{&quot;yql&quot; : &quot;select * from sources * where default contains \\&quot;music\\&quot;;&quot;}' \\http://localhost:8080/search/ | python -m json.tool 1$ curl -s 'http://localhost:8080/search/?yql=select+*+from+sources+*+where+default+contains+%22music%22%3B' | python -m json.tool 以上兩種都是利用搜尋 trump 出現在 default 欄位中的 item， 而這邊的 defaut 指的是我們在 sd 中所建立的 field set : default，當中包含了 title, content 兩個欄位，因此會對這兩個欄位進行 filter。 自定義排序功能 Relevance and Ranking，我們可以藉由自定義排功能，根據不同欄位計算相對應的權重，計算文章的相關性，用以實現自己想要的排序結果。 首先我們在先前定義好的SD 檔中新增 popularity 欄位，以及新的排序公式 123field popularity type double { indexing: summary | attribute} 12345rank-profile post_popularity inherits default { first-phase { expression: nativeRank(title, content) + 10 * if(isNan(attribute(popularity)), 0, attribute(popularity)) }} 我們新增了一條公式，繼承原本的rank-profile，並且覆寫掉第一階段的排序，將原本計算的分數加上 10 * popularity 欄位的值作為新的排序依據。 將新的應用部屬 12$ docker exec vespa bash -c '/opt/vespa/bin/vespa-deploy prepare /app/application &amp;&amp; \\ /opt/vespa/bin/vespa-deploy activate' Feeding 含有popularity 的文件 12345$ python sample-apps/blog-tutorial-shared/src/python/parse.py \\ -p sample-apps/blog-tutorial-shared/sample_posts.json &gt; tutorial_feed_with_popularity.json$ docker exec vespa bash -c 'java -jar /opt/vespa/lib/jars/vespa-http-client-jar-with-dependencies.jar \\ --verbose --file /app/tutorial_feed_with_popularity.json --host localhost --port 8080' 完成後我們再進行 curl ，比較新舊query profile 的差異 原本的返回結果 1curl -s -H &quot;Content-Type: application/json&quot; --data '{&quot;yql&quot; : &quot;select title, content, popularity from sources * where default contains \\&quot;music\\&quot;;&quot;}' http://localhost:8080/search/ | json_pp 使用新的popularity rank profile 的結果 12curl -s -H &quot;Content-Type: application/json&quot; --data '{&quot;yql&quot; : &quot;select * from sources * where default contains \\&quot;music\\&quot;;&quot;, &quot;ranking&quot; : &quot;post_popularity&quot;}' \\http://localhost:8080/search/ | json_pp 我們可以發現套用了post_popularity 的 rank-profile 排序變成給予popularity 的 item 較高排序權重，即便 content 跟 title 中都沒有出現相對應的搜尋文字。 左:default rank profile 右:使用popularity rank profile 至此我們已經完成了 環境搭建 Vespa 引擎設定 部屬應用 Feeding 資料 利用 YQL 進行簡單的搜尋 自訂義排序 下篇文章會繼續實做個人化的推薦系統~ 結論沒意外的話應該會將剩餘的內容切分到下幾篇文章 XD，本身對 Vespa 的用法也只是摸到皮毛，當中內部許多功能的實現方法也還沒有深入的研究，一樣還在持續的學習中，若文章中有錯誤的地方希望能鞭小力點XD，現今開源引擎較廣為人知的是 Elasticsearch, SOLR ， 然而 Vespa 的出現也提供了開發者一個新的選擇 ~ References https://vespa.ai/ https://cord19.vespa.ai/ https://towardsdatascience.com/vespa-ai-and-the-cord-19-public-api-a714b942172f","link":"/20200802/vepsa_note_1/"}],"tags":[{"name":"Japan","slug":"Japan","link":"/tags/Japan/"},{"name":"Kyushu","slug":"Kyushu","link":"/tags/Kyushu/"},{"name":"Shopping","slug":"Shopping","link":"/tags/Shopping/"},{"name":"EC","slug":"EC","link":"/tags/EC/"},{"name":"e-commerce","slug":"e-commerce","link":"/tags/e-commerce/"},{"name":"Taobao","slug":"Taobao","link":"/tags/Taobao/"},{"name":"test","slug":"test","link":"/tags/test/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"GCP","slug":"GCP","link":"/tags/GCP/"},{"name":"GAE","slug":"GAE","link":"/tags/GAE/"},{"name":"Google Cloud Platform","slug":"Google-Cloud-Platform","link":"/tags/Google-Cloud-Platform/"},{"name":"Google App Engine","slug":"Google-App-Engine","link":"/tags/Google-App-Engine/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Mega","slug":"Mega","link":"/tags/Mega/"},{"name":"Limit","slug":"Limit","link":"/tags/Limit/"},{"name":"Downloader","slug":"Downloader","link":"/tags/Downloader/"},{"name":"Tool","slug":"Tool","link":"/tags/Tool/"},{"name":"Api","slug":"Api","link":"/tags/Api/"},{"name":"Hack","slug":"Hack","link":"/tags/Hack/"},{"name":"CircleCI","slug":"CircleCI","link":"/tags/CircleCI/"},{"name":"DevOps","slug":"DevOps","link":"/tags/DevOps/"},{"name":"Software","slug":"Software","link":"/tags/Software/"},{"name":"CICD","slug":"CICD","link":"/tags/CICD/"},{"name":"google","slug":"google","link":"/tags/google/"},{"name":"guideline","slug":"guideline","link":"/tags/guideline/"},{"name":"code-review","slug":"code-review","link":"/tags/code-review/"},{"name":"pull-request","slug":"pull-request","link":"/tags/pull-request/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"PR","slug":"PR","link":"/tags/PR/"},{"name":"translation","slug":"translation","link":"/tags/translation/"},{"name":"翻譯","slug":"翻譯","link":"/tags/%E7%BF%BB%E8%AD%AF/"},{"name":"Icon","slug":"Icon","link":"/tags/Icon/"},{"name":"Design","slug":"Design","link":"/tags/Design/"},{"name":"zsh","slug":"zsh","link":"/tags/zsh/"},{"name":"mac","slug":"mac","link":"/tags/mac/"},{"name":"macos","slug":"macos","link":"/tags/macos/"},{"name":"homebrew","slug":"homebrew","link":"/tags/homebrew/"},{"name":"iterm2","slug":"iterm2","link":"/tags/iterm2/"},{"name":"powerlevel10k","slug":"powerlevel10k","link":"/tags/powerlevel10k/"},{"name":"oh-my-zsh","slug":"oh-my-zsh","link":"/tags/oh-my-zsh/"},{"name":"debug","slug":"debug","link":"/tags/debug/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"筆記","slug":"筆記","link":"/tags/%E7%AD%86%E8%A8%98/"},{"name":"Leetcode","slug":"Leetcode","link":"/tags/Leetcode/"},{"name":"Sort","slug":"Sort","link":"/tags/Sort/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"twitter","slug":"twitter","link":"/tags/twitter/"},{"name":"system design","slug":"system-design","link":"/tags/system-design/"},{"name":"interview","slug":"interview","link":"/tags/interview/"},{"name":"note","slug":"note","link":"/tags/note/"},{"name":"Vespa","slug":"Vespa","link":"/tags/Vespa/"},{"name":"Yahoo","slug":"Yahoo","link":"/tags/Yahoo/"},{"name":"Opensource","slug":"Opensource","link":"/tags/Opensource/"},{"name":"Search engine","slug":"Search-engine","link":"/tags/Search-engine/"},{"name":"Real time","slug":"Real-time","link":"/tags/Real-time/"}],"categories":[{"name":"Life","slug":"Life","link":"/categories/Life/"},{"name":"test","slug":"test","link":"/categories/test/"},{"name":"Tutorial","slug":"Tutorial","link":"/categories/Tutorial/"},{"name":"Note","slug":"Note","link":"/categories/Note/"},{"name":"Design","slug":"Design","link":"/categories/Design/"}]}